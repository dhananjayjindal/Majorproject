{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mealpy.optimizer import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: Solving single objective optimization problem.\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 1, Current best: 0.9994331120470065, Global best: 0.9994331120470065, Runtime: 0.00208 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 2, Current best: 0.9999991482625487, Global best: 0.9999991482625487, Runtime: 0.00182 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 3, Current best: 0.9999991482625487, Global best: 0.9999991482625487, Runtime: 0.00191 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 4, Current best: 0.9999991482625487, Global best: 0.9999991482625487, Runtime: 0.00216 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 5, Current best: 0.9999991482625487, Global best: 0.9999991482625487, Runtime: 0.00203 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 6, Current best: 0.9999991482625487, Global best: 0.9999991482625487, Runtime: 0.00266 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 7, Current best: 0.9999999490027462, Global best: 0.9999999490027462, Runtime: 0.00224 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 8, Current best: 0.9999999993843814, Global best: 0.9999999993843814, Runtime: 0.00192 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 9, Current best: 0.9999999999074485, Global best: 0.9999999999074485, Runtime: 0.00280 seconds\n",
      "2023/12/03 12:01:39 AM, INFO, __main__.OriginalHHO: >Problem: P, Epoch: 10, Current best: 0.9999999999074485, Global best: 0.9999999999074485, Runtime: 0.00228 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear Solutions: [1.57078272 3.14159265], Fitness: 0.9999999999074485\n"
     ]
    }
   ],
   "source": [
    "class OriginalHHO(Optimizer):\n",
    "    def __init__(self, epoch=10000, pop_size=100, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            epoch (int): maximum number of iterations, default = 10000\n",
    "            pop_size (int): number of population size, default = 100\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.epoch = self.validator.check_int(\"epoch\", epoch, [1, 100000])\n",
    "        self.pop_size = self.validator.check_int(\"pop_size\", pop_size, [10, 10000])\n",
    "        self.set_parameters([\"epoch\", \"pop_size\"])\n",
    "        self.sort_flag = False\n",
    "\n",
    "    def evolve(self, epoch):\n",
    "        \"\"\"\n",
    "        The main operations (equations) of the algorithm. Inherit from Optimizer class.\n",
    "        Args:\n",
    "            epoch (int): The current iteration\n",
    "        \"\"\"\n",
    "        pop_new = []\n",
    "        for idx in range(0, self.pop_size):\n",
    "            # -1 < E0 < 1\n",
    "            E0 = 2 * np.random.uniform() - 1\n",
    "            # factor to show the decreasing energy of rabbit\n",
    "            E = 2 * E0 * (1 - (epoch + 1) * 1.0 / self.epoch)\n",
    "            J = 2 * (1 - np.random.uniform())\n",
    "\n",
    "            # -------- Exploration phase Eq. (1) in paper -------------------\n",
    "            if np.abs(E) >= 1:\n",
    "                # Harris' hawks perch randomly based on 2 strategy:\n",
    "                if np.random.rand() >= 0.5:  # perch based on other family members\n",
    "                    X_rand = self.pop[np.random.randint(0, self.pop_size)][self.ID_POS].copy()\n",
    "                    pos_new = X_rand - np.random.uniform() * np.abs(X_rand - 2 * np.random.uniform() * self.pop[idx][self.ID_POS])\n",
    "                else:  # perch on a random tall tree (random site inside group's home range)\n",
    "                    X_m = np.mean([x[self.ID_POS] for x in self.pop])\n",
    "                    pos_new = (self.g_best[self.ID_POS] - X_m) - np.random.uniform() * \\\n",
    "                              (self.problem.lb + np.random.uniform() * (self.problem.ub - self.problem.lb))\n",
    "                # pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)\n",
    "                fitness_val = self.problem.fit_func(pos_new)\n",
    "                pop_new.append([pos_new, fitness_val])\n",
    "            # -------- Exploitation phase -------------------\n",
    "            else:\n",
    "                # Attacking the rabbit using 4 strategies regarding the behavior of the rabbit\n",
    "                # phase 1: ----- surprise pounce (seven kills) ----------\n",
    "                # surprise pounce (seven kills): multiple, short rapid dives by different hawks\n",
    "                if (np.random.rand() >= 0.5):\n",
    "                    delta_X = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]\n",
    "                    if np.abs(E) >= 0.5:  # Hard besiege Eq. (6) in paper\n",
    "                        pos_new = delta_X - E * np.abs(J * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])\n",
    "                    else:  # Soft besiege Eq. (4) in paper\n",
    "                        pos_new = self.g_best[self.ID_POS] - E * np.abs(delta_X)\n",
    "                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)\n",
    "                    pop_new.append([pos_new, None])\n",
    "                else:\n",
    "                    LF_D = self.get_levy_flight_step(beta=1.5, multiplier=0.01, case=-1)\n",
    "                    if np.abs(E) >= 0.5:  # Soft besiege Eq. (10) in paper\n",
    "                        Y = self.g_best[self.ID_POS] - E * np.abs(J * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])\n",
    "                    else:  # Hard besiege Eq. (11) in paper\n",
    "                        X_m = np.mean([x[self.ID_POS] for x in self.pop])\n",
    "                        Y = self.g_best[self.ID_POS] - E * np.abs(J * self.g_best[self.ID_POS] - X_m)\n",
    "                    pos_Y = self.amend_position(Y, self.problem.lb, self.problem.ub)\n",
    "                    target_Y = self.get_target_wrapper(pos_Y)\n",
    "                    Z = Y + np.random.uniform(self.problem.lb, self.problem.ub) * LF_D\n",
    "                    pos_Z = self.amend_position(Z, self.problem.lb, self.problem.ub)\n",
    "                    target_Z = self.get_target_wrapper(pos_Z)\n",
    "                    if self.compare_agent([pos_Y, target_Y], self.pop[idx]):\n",
    "                        pop_new.append([pos_Y, target_Y])\n",
    "                        continue\n",
    "                    if self.compare_agent([pos_Z, target_Z], self.pop[idx]):\n",
    "                        pop_new.append([pos_Z, target_Z])\n",
    "                        continue\n",
    "                    pop_new.append(self.pop[idx].copy())\n",
    "\n",
    "        if self.mode not in self.AVAILABLE_MODES:\n",
    "            for idx, agent in enumerate(pop_new):\n",
    "                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])\n",
    "        else:\n",
    "            pop_new = self.update_target_wrapper_population(pop_new)\n",
    "        self.pop = self.greedy_selection_population(self.pop, pop_new)\n",
    "\n",
    "def nonlinear_fitness_function(solution):\n",
    "    x, y = solution\n",
    "    return -(np.sin(x) * np.cos(y))  # Example: Minimize a simple nonlinear function\n",
    "\n",
    "# Update the problem dictionary with the new fitness function\n",
    "nonlinear_problem_dict = {\n",
    "    \"fit_func\": nonlinear_fitness_function,\n",
    "    \"lb\": [0, 0],\n",
    "    \"ub\": [2 * np.pi, np.pi],\n",
    "    \"minmax\": \"max\",  # Use \"min\" for minimization problems\n",
    "}\n",
    "\n",
    "# Set the number of epochs and population size\n",
    "nonlinear_epoch = 10\n",
    "nonlinear_pop_size = 50\n",
    "\n",
    "# Create a new instance of OriginalHHO with the updated problem\n",
    "nonlinear_model = OriginalHHO(nonlinear_epoch, nonlinear_pop_size)\n",
    "nonlinear_best_position, nonlinear_best_fitness = nonlinear_model.solve(nonlinear_problem_dict)\n",
    "\n",
    "print(f\"Nonlinear Solutions: {nonlinear_best_position}, Fitness: {nonlinear_best_fitness}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
